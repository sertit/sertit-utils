<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1"/>
<meta name="generator" content="pdoc 0.9.2"/>
<title>sertit.files API documentation</title>
<meta name="description" content="Tools for paths and files"/>
<link rel="preload stylesheet" as="style"
href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style"
href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style"
href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/darcula.min.css"
crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100%;padding:3em 4em;border-left:1px solid #ddd;overflow-x:hidden}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}table{display:block;overflow-x:auto;word-break:keep-all;border-collapse:separate;border-spacing:0}th{background-color:#c4d5e780;padding:5px;border-bottom:0.1px solid gray;border-right:0.1px solid gray;border-top:0.1px solid gray}td,th{margin:0}td{white-space:nowrap;border-bottom:0.1px solid gray;border-right:0.1px solid gray}td:empty{background-color:#ececec}th:nth-child(1){border-left:0.1px solid gray}td:nth-child(1){border-left:0.1px solid gray;border-right:0.1px solid gray}th:nth-child(1),td:nth-child(1){background-color:#c4d5e7;position:-webkit-sticky;position:sticky;left:0}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML"
integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"
integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sertit.files</code></h1>
</header>
<section id="section-intro">
<p>Tools for paths and files</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
# Copyright 2021, SERTIT-ICube - France, https://sertit.unistra.fr/
# This file is part of sertit-utils project
#     https://github.com/sertit/sertit-utils
#
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
&#34;&#34;&#34; Tools for paths and files &#34;&#34;&#34;

import hashlib
import json
import logging
import os
import pickle
import pprint
import re
import shutil
import tarfile
import tempfile
import zipfile
from datetime import date, datetime
from enum import Enum
from json import JSONDecoder, JSONEncoder
from pathlib import Path
from typing import Any, Union

import numpy as np
from cloudpathlib import AnyPath, CloudPath
from lxml import etree
from tqdm import tqdm

from sertit import misc
from sertit.logs import SU_NAME

LOGGER = logging.getLogger(SU_NAME)


def get_root_path() -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Get the root path of the current disk:

    - On Linux this returns `/`
    - On Windows this returns `C:\\` or whatever the current drive is

    ```python
    &gt;&gt;&gt; get_root_path()
    &#34;/&#34; on Linux
    &#34;C:\\&#34; on Windows (if you run this code from the C: drive)
    ```
    &#34;&#34;&#34;
    return AnyPath(os.path.abspath(os.sep))


def listdir_abspath(directory: Union[str, CloudPath, Path]) -&gt; list:
    &#34;&#34;&#34;
    Get absolute path of all files in the given directory.

    It is the same function than `os.listdir` but returning absolute paths.

    ```python
    &gt;&gt;&gt; folder = &#34;.&#34;
    &gt;&gt;&gt; listdir_abspath(folder)
    [&#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\files.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\logs.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\misc.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\network.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\rasters_rio.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\strings.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\vectors.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\version.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\__init__.py&#39;]
    ```

    Args:
        directory (Union[str, CloudPath, Path]): Relative or absolute path to the directory to be scanned

    Returns:
        str: Absolute path of all files in the given directory
    &#34;&#34;&#34;
    dirpath = AnyPath(directory)

    return list(dirpath.iterdir())


def to_abspath(
    path: Union[str, CloudPath, Path], create: bool = True
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Return the absolute path of the specified path and check if it exists

    If not:

    - If it is a file (aka has an extension), it raises an exception
    - If it is a folder, it creates it

    To be used with argparse to retrieve the absolute path of a file, like:

    ```python
    &gt;&gt;&gt; parser = argparse.ArgumentParser()
    &gt;&gt;&gt; # Add config file path key
    &gt;&gt;&gt; parser.add_argument(&#34;--config&#34;,
                            help=&#34;Config file path (absolute or relative)&#34;,
                            type=to_abspath)
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path as a string (relative or absolute)
        create (bool): Create directory if not existing

    Returns:
        Union[CloudPath, Path]: Absolute path
    &#34;&#34;&#34;
    abs_path = AnyPath(path).resolve()

    if not abs_path.exists():
        if abs_path.suffix:
            # If the path specifies a file (with extension), it raises an exception
            raise FileNotFoundError(f&#34;Non existing file: {abs_path}&#34;)

        # If the path specifies a folder, it creates it
        if create:
            abs_path.mkdir()

    return abs_path


def real_rel_path(
    path: Union[str, CloudPath, Path], start: Union[str, CloudPath, Path]
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Gives the real relative path from a starting folder.
    (and not just adding `..\..` between the start and the target)

    ```python
    &gt;&gt;&gt; path = r&#39;D:\_SERTIT_UTILS\sertit-utils\sertit&#39;
    &gt;&gt;&gt; start = os.path.join(&#34;.&#34;, &#34;..&#34;, &#34;..&#34;)
    &gt;&gt;&gt; real_rel_path(path, start)
    &#39;sertit-utils\\sertit&#39;
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path to make relative
        start (Union[str, CloudPath, Path]): Start, the path being relative from this folder.

    Returns:
        Relative path
    &#34;&#34;&#34;
    path = AnyPath(path)
    start = AnyPath(start)
    rel_path = path
    if not isinstance(path, CloudPath) and not isinstance(start, CloudPath):
        rel_path = path.resolve().relative_to(start.resolve())

    return rel_path


def extract_file(
    file_path: Union[str, CloudPath, Path],
    output: Union[str, CloudPath, Path],
    overwrite: bool = False,
) -&gt; Union[list, CloudPath, Path]:
    &#34;&#34;&#34;
    Extract an archived file (zip or others). Overwrites if specified.
    For zipfiles, in case of multiple folders archived, pay attention that what is returned is the first folder.

    ```python
    &gt;&gt;&gt; file_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; output = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; extract_file(file_path, output, overwrite=True)
    D:\\path\\to\\output\zip&#39;
    ```

    Args:
        file_path (str): Archive file path
        output (str): Output where to put the extracted file
        overwrite (bool): Overwrite found extracted files

    Returns:
        Union[list, CloudPath, Path]: Extracted file paths (as str if only one)
    &#34;&#34;&#34;
    # Convert to path
    file_path = AnyPath(file_path)
    output = AnyPath(output)

    # In case a folder is given, returns it (this means that the file is already extracted)
    if file_path.is_dir():
        return file_path

    # Manage archive type
    if file_path.suffix == &#34;.zip&#34;:
        # Manage the case with several directories inside one zipfile
        arch = zipfile.ZipFile(file_path, &#34;r&#34;)
        extr_names = list({path.split(&#34;/&#34;)[0] for path in arch.namelist()})
    elif file_path.suffix == &#34;.tar&#34; or file_path.suffixes == [&#34;.tar&#34;, &#34;.gz&#34;]:
        # Tar files have no subdirectories, so create one
        extr_names = [get_filename(file_path)]
        arch = tarfile.open(file_path, &#34;r&#34;)
    else:
        raise TypeError(
            f&#34;Only .zip, .tar and .tar.gz files can be extracted, not {file_path}&#34;
        )

    # Get extracted list
    extr_dirs = [output.joinpath(extr_name) for extr_name in extr_names]

    # Loop over basedirs from inside the archive
    for extr_dir in extr_dirs:
        extr_name = extr_dir.name
        # Manage overwriting
        if extr_dir.is_dir():
            if overwrite:
                LOGGER.debug(
                    &#34;Already existing extracted %s. It will be overwritten as asked.&#34;,
                    extr_names,
                )
                remove(extr_dir)
            else:
                LOGGER.debug(
                    &#34;Already existing extracted %s. It won&#39;t be overwritten.&#34;,
                    extr_names,
                )

        else:
            LOGGER.info(&#34;Extracting %s&#34;, extr_names)
            # Inside docker, extracting files is really slow -&gt; copy the archive in a tmp directory
            with tempfile.TemporaryDirectory() as tmp_dir:
                if misc.in_docker():
                    # Create a tmp directory
                    copy(file_path, tmp_dir)
                    file_path = os.path.join(tmp_dir, os.path.basename(file_path))
                    tmp_extr_output = tmp_dir

                    # Recreate dir with tmp output
                    tmp_extr_dir = os.path.join(tmp_extr_output, extr_name)
                else:
                    tmp_extr_output = output
                    tmp_extr_dir = extr_dir

                if str(file_path).endswith(&#34;.zip&#34;):
                    members = [name for name in arch.namelist() if extr_name in name]
                else:
                    members = arch.getmembers()  # Always extract all files for TAR data

                    # Tar files do not contain a file tree
                    tmp_extr_output = tmp_extr_dir

                # Extract product
                try:
                    os.makedirs(tmp_extr_dir, exist_ok=True)
                    arch.extractall(path=tmp_extr_output, members=members)
                except tarfile.ReadError as ex:
                    raise TypeError(f&#34;Impossible to extract {file_path}&#34;) from ex

                # Copy back if we are running inside docker and clean tmp dir
                if misc.in_docker():
                    copy(tmp_extr_dir, extr_dir)

    # Close archive
    arch.close()

    # Return str for compatibility reasons
    if len(extr_dirs) == 1:
        extr_dirs = extr_dirs[0]

    return extr_dirs


def extract_files(
    archives: list, output: Union[str, CloudPath, Path], overwrite: bool = False
) -&gt; list:
    &#34;&#34;&#34;
    Extract all archived files. Overwrites if specified.

    ```python
    &gt;&gt;&gt; file_path = [&#39;D:\\path\\to\\zip1.zip&#39;, &#39;D:\\path\\to\\zip2.zip&#39;]
    &gt;&gt;&gt; output = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; extract_files(file_path, output, overwrite=True)
    [&#39;D:\\path\\to\\output\zip1&#39;, &#39;D:\\path\\to\\output\zip2&#39;]
    ```

    Args:
        archives (list of str): List of archives to be extracted
        output (str): Output folder where extracted files will be written
        overwrite (bool): Overwrite found extracted files

    Returns:
        list: Extracted files (even pre-existing ones)
    &#34;&#34;&#34;
    LOGGER.info(&#34;Extracting products in %s&#34;, output)
    progress_bar = tqdm(archives)
    extracts = []
    for arch in progress_bar:
        progress_bar.set_description(f&#34;Extracting product {os.path.basename(arch)}&#34;)
        extracts.append(extract_file(arch, output, overwrite))

    return extracts


def get_archived_file_list(archive_path: Union[str, CloudPath, Path]) -&gt; list:
    &#34;&#34;&#34;
    Get the list of all the files contained in an archive.

    ```python
    &gt;&gt;&gt; arch_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; get_archived_file_list(arch_path, file_regex)
    [&#39;file_1.txt&#39;, &#39;file_2.tif&#39;, &#39;file_3.xml&#39;, &#39;file_4.geojson&#39;]
    ```

    Args:
        archive_path (Union[str, CloudPath, Path]): Archive path

    Returns:
        list: All files contained in the given archive
    &#34;&#34;&#34;
    archive_path = AnyPath(archive_path)
    if archive_path.suffix == &#34;.zip&#34;:
        with zipfile.ZipFile(archive_path) as zip_ds:
            file_list = [f.filename for f in zip_ds.filelist]
    else:
        try:
            with tarfile.open(archive_path) as tar_ds:
                tar_mb = tar_ds.getmembers()
                file_list = [mb.name for mb in tar_mb]
        except tarfile.ReadError as ex:
            raise TypeError(f&#34;Impossible to open archive: {archive_path}&#34;) from ex

    return file_list


def get_archived_rio_path(
    archive_path: Union[str, CloudPath, Path], file_regex: str, as_list: bool = False
) -&gt; Union[list, CloudPath, Path]:
    &#34;&#34;&#34;
    Get archived file path from inside the archive, to be read with rasterio:

    - `zip+file://{zip_path}!{file_name}`
    - `tar+file://{tar_path}!{file_name}`

    See [here](https://rasterio.readthedocs.io/en/latest/topics/datasets.html?highlight=zip#dataset-identifiers)
    for more information.

    .. WARNING::
        It wont be readable by pandas, geopandas or xmltree !

    .. WARNING::
        If `as_list` is `False`, it will only return the first file matched !

    You can use this [site](https://regexr.com/) to build your regex.

    ```python
    &gt;&gt;&gt; arch_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; file_regex = &#39;.*dir.*file_name&#39;  # Use .* for any character
    &gt;&gt;&gt; path = get_archived_tif_path(arch_path, file_regex)
    &#39;zip+file://D:\\path\\to\\output\zip!dir/filename.tif&#39;
    &gt;&gt;&gt; rasterio.open(path)
    &lt;open DatasetReader name=&#39;zip+file://D:\\path\\to\\output\zip!dir/filename.tif&#39; mode=&#39;r&#39;&gt;
    ```

    Args:
        archive_path (Union[str, CloudPath, Path]): Archive path
        file_regex (str): File regex (used by re) as it can be found in the getmembers() list
        as_list (bool): If true, returns a list (including all found files). If false, returns only the first match

    Returns:
        Union[list, str]: Band path that can be read by rasterio
    &#34;&#34;&#34;
    # Get file list
    archive_path = AnyPath(archive_path)
    file_list = get_archived_file_list(archive_path)

    if archive_path.suffix in [&#34;.tar&#34;, &#34;.zip&#34;]:
        prefix = archive_path.suffix[-3:]
    elif archive_path.suffix == &#34;.tar.gz&#34;:
        raise TypeError(
            &#34;.tar.gz files are too slow to be read from inside the archive. Please extract them instead.&#34;
        )
    else:
        raise TypeError(&#34;Only .zip and .tar files can be read from inside its archive.&#34;)

    # Search for file
    regex = re.compile(file_regex)
    archived_band_path = list(filter(regex.match, file_list))
    if not archived_band_path:
        raise FileNotFoundError(
            f&#34;Impossible to find file {file_regex} in {get_filename(archive_path)}&#34;
        )

    # Convert to rio path
    if isinstance(archive_path, CloudPath):
        archived_band_path = [
            f&#34;{prefix}+file+{archive_path}!{path}&#34; for path in archived_band_path
        ]
    else:
        archived_band_path = [
            f&#34;{prefix}+file://{archive_path}!{path}&#34; for path in archived_band_path
        ]

    # Convert to str if needed
    if not as_list:
        archived_band_path = archived_band_path[0]

    return archived_band_path


def read_archived_xml(
    archive_path: Union[str, CloudPath, Path], xml_regex: str
) -&gt; etree._Element:
    &#34;&#34;&#34;
    Read archived XML from `zip` or `tar` archives.

    You can use this [site](https://regexr.com/) to build your regex.

    ```python
    &gt;&gt;&gt; arch_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; file_regex = &#39;.*dir.*file_name&#39;  # Use .* for any character
    &gt;&gt;&gt; read_archived_xml(arch_path, file_regex)
    &lt;Element LANDSAT_METADATA_FILE at 0x1c90007f8c8&gt;
    ```

    Args:
        archive_path (Union[str, CloudPath, Path]): Archive path
        xml_regex (str): XML regex (used by re) as it can be found in the getmembers() list

    Returns:
         etree._Element: XML file
    &#34;&#34;&#34;
    archive_path = AnyPath(archive_path)

    # Compile regex
    regex = re.compile(xml_regex)

    # Open tar and zip XML
    try:
        if archive_path.suffix == &#34;.tar&#34;:
            with tarfile.open(archive_path) as tar_ds:
                tar_mb = tar_ds.getmembers()
                name_list = [mb.name for mb in tar_mb]
                band_name = list(filter(regex.match, name_list))[0]
                tarinfo = [mb for mb in tar_mb if mb.name == band_name][0]
                xml_str = tar_ds.extractfile(tarinfo).read()
        elif archive_path.suffix == &#34;.zip&#34;:
            with zipfile.ZipFile(archive_path) as zip_ds:
                name_list = [f.filename for f in zip_ds.filelist]
                band_name = list(filter(regex.match, name_list))[0]
                xml_str = zip_ds.read(band_name)

        elif archive_path.suffix == &#34;.tar.gz&#34;:
            raise TypeError(
                &#34;.tar.gz files are too slow to read from inside the archive. Please extract them instead.&#34;
            )
        else:
            raise TypeError(
                &#34;Only .zip and .tar files can be read from inside its archive.&#34;
            )
    except IndexError:
        raise FileNotFoundError(
            f&#34;Impossible to find XML file {xml_regex} in {get_filename(archive_path)}&#34;
        )

    return etree.fromstring(xml_str)


def archive(
    folder_path: Union[str, CloudPath, Path],
    archive_path: Union[str, CloudPath, Path],
    fmt: str = &#34;zip&#34;,
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Archives a folder recursively.

    ```python
    &gt;&gt;&gt; folder_path = &#39;D:\\path\\to\\folder_to_archive&#39;
    &gt;&gt;&gt; archive_path = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; archive = archive(folder_path, archive_path, fmt=&#34;gztar&#34;)
    &#39;D:\\path\\to\\output\\folder_to_archive.tar.gz&#39;
    ```

    Args:
        folder_path (Union[str, CloudPath, Path]): Folder to archive
        archive_path (Union[str, CloudPath, Path]): Archive path, with or without extension
        fmt (str): Format of the archive, used by `shutil.make_archive`. Choose between [zip, tar, gztar, bztar, xztar]
    Returns:
        str: Archive filename
    &#34;&#34;&#34;
    archive_path = AnyPath(archive_path)
    folder_path = AnyPath(folder_path)

    # Shutil make_archive needs a path without extension
    archive_base = os.path.splitext(archive_path)[0]

    # Archive the folder
    archive_fn = shutil.make_archive(
        archive_base,
        format=fmt,
        root_dir=folder_path.parent,
        base_dir=folder_path.name,
    )

    return AnyPath(archive_fn)


def add_to_zip(
    zip_path: Union[str, CloudPath, Path],
    dirs_to_add: Union[list, str, CloudPath, Path],
) -&gt; None:
    &#34;&#34;&#34;
    Add folders to an already existing zip file (recursively).

    ```python
    &gt;&gt;&gt; zip_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; dirs_to_add = [&#39;D:\\path\\to\\dir1&#39;, &#39;D:\\path\\to\\dir2&#39;]
    &gt;&gt;&gt; add_to_zip(zip_path, dirs_to_add)
    &gt;&gt;&gt; # zip.zip contains 2 more folders, dir1 and dir2
    ```

    Args:
        zip_path (Union[str, CloudPath, Path]): Already existing zip file
        dirs_to_add (Union[list, str]): Directories to add
    &#34;&#34;&#34;
    zip_path = AnyPath(zip_path)

    # Check if existing zipfile
    if not zip_path.is_file():
        raise FileNotFoundError(f&#34;Non existing {zip_path}&#34;)

    # Convert to list if needed
    if not isinstance(dirs_to_add, list):
        dirs_to_add = [dirs_to_add]

    # Add all folders to the existing zip
    # Forced to use ZipFile because make_archive only works with one folder and not existing zipfile
    with zipfile.ZipFile(zip_path, &#34;a&#34;) as zip_file:
        progress_bar = tqdm(dirs_to_add)
        for dir_to_add in progress_bar:
            progress_bar.set_description(
                f&#34;Adding {os.path.basename(dir_to_add)} to {os.path.basename(zip_path)}&#34;
            )
            for root, _, files in os.walk(dir_to_add):
                base_path = os.path.join(dir_to_add, &#34;..&#34;)

                # Write dir (in namelist at least)
                zip_file.write(root, os.path.relpath(root, base_path))

                # Write files
                for file in files:
                    zip_file.write(
                        os.path.join(root, file),
                        os.path.relpath(
                            os.path.join(root, file), os.path.join(dir_to_add, &#34;..&#34;)
                        ),
                    )


def get_filename(file_path: Union[str, CloudPath, Path]) -&gt; str:
    &#34;&#34;&#34;
    Get file name (without extension) from file path, ie:

    ```python
    &gt;&gt;&gt; file_path = &#39;D:\\path\\to\\filename.zip&#39;
    &gt;&gt;&gt; get_file_name(file_path)
    &#39;filename&#39;
    ```

    Args:
        file_path (Union[str, CloudPath, Path]): Absolute or relative file path (the file doesn&#39;t need to exist)

    Returns:
        str: File name (without extension)
    &#34;&#34;&#34;
    file_path = AnyPath(file_path)

    # We need to avoid splitext because of nested extensions such as .tar.gz
    return file_path.name.split(&#34;.&#34;)[0]


def remove(path: Union[str, CloudPath, Path]) -&gt; None:
    &#34;&#34;&#34;
    Deletes a file or a directory (recursively) using `shutil.rmtree` or `os.remove`.

    ```python
    &gt;&gt;&gt; path_to_remove = &#39;D:\\path\\to\\remove&#39;  # Could also be a file
    &gt;&gt;&gt; remove(path_to_remove)
    path_to_remove deleted
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path to be removed
    &#34;&#34;&#34;
    path = AnyPath(path)
    if not path.exists():
        LOGGER.debug(&#34;Non existing %s&#34;, path)

    elif path.is_dir():
        try:
            shutil.rmtree(path)
        except OSError:
            LOGGER.debug(&#34;Impossible to remove the directory %s&#34;, path, exc_info=True)

    elif path.is_file():
        try:
            path.unlink()
        except OSError:
            LOGGER.debug(&#34;Impossible to remove the file %s&#34;, path, exc_info=True)


def remove_by_pattern(
    directory: Union[str, CloudPath, Path],
    name_with_wildcard: str = &#34;*&#34;,
    extension: str = None,
) -&gt; None:
    &#34;&#34;&#34;
    Remove files corresponding to a pattern from a directory.

    ```python
    &gt;&gt;&gt; directory = &#39;D:\\path\\to\\folder&#39;
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;huhu.exe&#34;, &#34;blabla.geojson&#34;, &#34;haha.txt&#34;, &#34;blabla&#34;]

    &gt;&gt;&gt; remove(directory, &#34;blabla*&#34;)
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;huhu.exe&#34;, &#34;haha.txt&#34;] # Removes also directories

    &gt;&gt;&gt; remove(directory, &#34;*&#34;, extension=&#34;txt&#34;)
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;huhu.exe&#34;]
    ```

    Args:
        directory (Union[str, CloudPath, Path]): Directory where to find the files
        name_with_wildcard (str): Filename (wildcards accepted)
        extension (str): Extension wanted, optional. With or without point. (yaml or .yaml accepted)
    &#34;&#34;&#34;
    directory = AnyPath(directory)
    if extension and not extension.startswith(&#34;.&#34;):
        extension = &#34;.&#34; + extension

    file_list = directory.glob(name_with_wildcard + extension)
    for file in file_list:
        remove(file)


def copy(
    src: Union[str, CloudPath, Path], dst: Union[str, CloudPath, Path]
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Copy a file or a directory (recursively) with `copytree` or `copy2`.

    ```python
    &gt;&gt;&gt; src = &#39;D:\\path\\to\\copy&#39;
    &gt;&gt;&gt; dst = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; copy(src, dst)
    copydir &#39;D:\\path\\to\\output\\copy&#39;

    &gt;&gt;&gt; src = &#39;D:\\path\\to\\copy.txt&#39;
    &gt;&gt;&gt; dst = &#39;D:\\path\\to\\output\\huhu.txt&#39;
    &gt;&gt;&gt; copyfile = copy(src, dst)
    &#39;D:\\path\\to\\output\\huhu.txt&#39; but with the content of copy.txt
    ```

    Args:
        src (Union[str, CloudPath, Path]): Source Path
        dst (Union[str, CloudPath, Path]): Destination Path (file or folder)

    Returns:
        Union[CloudPath, Path]: New path
    &#34;&#34;&#34;
    src = AnyPath(src)
    out = None
    try:
        if src.is_dir():
            out = AnyPath(shutil.copytree(src, dst))
        elif os.path.isfile(src):
            out = AnyPath(shutil.copy2(src, dst))
    except shutil.Error:
        LOGGER.debug(exc_info=True)
        out = src
        # eg. source or destination doesn&#39;t exist
    except IOError as ex:
        raise IOError(f&#34;Copy error: {ex.strerror}&#34;) from ex

    return out


def find_files(
    names: Union[list, str],
    root_paths: Union[list, str, CloudPath, Path],
    max_nof_files: int = -1,
    get_as_str: bool = False,
) -&gt; Union[list, str]:
    &#34;&#34;&#34;
    Returns matching files recursively from a list of root paths.

    Regex are allowed (using glob)

    ```python
    &gt;&gt;&gt; root_path = &#39;D:\\root&#39;
    &gt;&gt;&gt; dir1_path = &#39;D:\\root\\dir1&#39;
    &gt;&gt;&gt; dir2_path = &#39;D:\\root\\dir2&#39;

    &gt;&gt;&gt; os.listdir(dir1_path)
    [&#34;haha.txt&#34;, &#34;huhu.txt&#34;, &#34;hoho.txt&#34;]
    &gt;&gt;&gt; os.listdir(dir2_path)
    [&#34;huhu.txt&#34;, &#34;hehe.txt&#34;]

    &gt;&gt;&gt; find_files(&#34;huhu.txt&#34;, root_path)
    [&#39;D:\\root\\dir1\\huhu.txt&#39;, &#39;D:\\root\\dir2\\huhu.txt&#39;]

    &gt;&gt;&gt; find_files(&#34;huhu.txt&#34;, root_path, max_nof_files=1)
    [&#39;D:\\root\\dir1\\huhu.txt&#39;]

    &gt;&gt;&gt; find_files(&#34;huhu.txt&#34;, root_path, max_nof_files=1, get_as_str=True)
    found = &#39;D:\\root\\dir1\\huhu.txt&#39;
    ```

    Args:
        names (Union[list, str]): File names.
        root_paths (Union[list, str]): Root paths
        max_nof_files (int): Maximum number of files (set to -1 for unlimited)
        get_as_str (bool): if only one file is found, it can be retrieved as a string instead of a list

    Returns:
        list: File name
    &#34;&#34;&#34;
    paths = []

    # Transform to list
    if not isinstance(names, list):
        names = [names]

    if not isinstance(root_paths, list):
        root_paths = [root_paths]

    try:
        for root_path in root_paths:
            root_path = AnyPath(root_path)
            for name in names:
                paths += list(root_path.glob(f&#34;**/*{name}*&#34;))

    except StopIteration:
        pass

    # Check if found
    if not paths:
        raise FileNotFoundError(f&#34;Files {names} not found in {root_paths}&#34;)

    if max_nof_files &gt; 0:
        paths = paths[:max_nof_files]

    LOGGER.debug(
        &#34;Paths found in %s for filenames %s:\n%s&#34;,
        root_paths,
        names,
        pprint.pformat(paths),
    )

    # Get str if needed
    if len(paths) == 1 and get_as_str:
        paths = paths[0]

    return paths


# subclass JSONDecoder
class CustomDecoder(JSONDecoder):
    &#34;&#34;&#34;Decoder for JSON with methods for datetimes&#34;&#34;&#34;

    # pylint: disable=W0221
    # Override the default method
    def __init__(self, *args, **kwargs):
        json.JSONDecoder.__init__(self, object_hook=self.object_hook, *args, **kwargs)

    # pylint: disable=E0202, R0201
    # - An attribute defined in json.decoder line 319 hides this method (method-hidden)
    # - Method could be a function (no-self-use)
    def object_hook(self, obj: Any):
        &#34;&#34;&#34;
        Overload of object_hook function that deals with `datetime.datetime`

        Args:
            obj (dict): Dict containing objects to decode from JSON

        Returns:
            dict: Dict with decoded object
        &#34;&#34;&#34;
        for key, val in obj.items():
            if isinstance(val, str):
                try:
                    # Date -&gt; Encoder saves dates as isoformat
                    obj[key] = date.fromisoformat(val)
                except ValueError:
                    try:
                        # Datetime -&gt; Encoder saves datetimes as isoformat
                        obj[key] = datetime.fromisoformat(val)
                    except ValueError:
                        obj[key] = val
            else:
                obj[key] = val
        return obj


# subclass JSONEncoder
class CustomEncoder(JSONEncoder):
    &#34;&#34;&#34;Encoder for JSON with methods for datetimes and np.int64&#34;&#34;&#34;

    # pylint: disable=W0221
    def default(self, obj):
        &#34;&#34;&#34;Overload of the default method&#34;&#34;&#34;
        if isinstance(obj, (date, datetime)):
            out = obj.isoformat()
        elif isinstance(obj, (np.int64, np.int32)):
            out = int(obj)
        elif isinstance(obj, Enum):
            out = obj.value
        elif isinstance(obj, (CloudPath, Path)):
            out = str(obj)
        else:
            out = json.JSONEncoder.default(self, obj)

        return out


def read_json(json_file: Union[str, CloudPath, Path], print_file: bool = True) -&gt; dict:
    &#34;&#34;&#34;
    Read a JSON file

    ```python
    &gt;&gt;&gt; json_path = &#39;D:\\path\\to\\json.json&#39;
    &gt;&gt;&gt; read_json(json_path, print_file=False)
    {&#34;A&#34;: 1, &#34;B&#34;: 2}
    ```

    Args:
        json_file (Union[str, CloudPath, Path]): Path to JSON file
        print_file (bool):  Print the configuration file

    Returns:
        dict: JSON data
    &#34;&#34;&#34;

    with open(json_file) as file:
        data = json.load(file, cls=CustomDecoder)
        if print_file:
            LOGGER.debug(
                &#34;Configuration file %s contains:\n%s&#34;,
                json_file,
                json.dumps(data, indent=3, cls=CustomEncoder),
            )
    return data


def save_json(output_json: Union[str, CloudPath, Path], json_dict: dict) -&gt; None:
    &#34;&#34;&#34;
    Save a JSON file, with datetime, numpy types and Enum management.

    ```python
    &gt;&gt;&gt; output_json = &#39;D:\\path\\to\\json.json&#39;
    &gt;&gt;&gt; json_dict = {&#34;A&#34;: np.int64(1), &#34;B&#34;: datetime.today(), &#34;C&#34;: SomeEnum.some_name}
    &gt;&gt;&gt; save_json(output_json, json_dict)
    ```

    Args:
        output_json (Union[str, CloudPath, Path]): Output file
        json_dict (dict): Json dictionary
    &#34;&#34;&#34;

    with open(output_json, &#34;w&#34;) as output_config_file:
        json.dump(json_dict, output_config_file, indent=3, cls=CustomEncoder)


def save_obj(obj: Any, path: Union[str, CloudPath, Path]) -&gt; None:
    &#34;&#34;&#34;
    Save an object as a pickle (can save any Python objects).

    ```python
    &gt;&gt;&gt; output_pkl = &#39;D:\\path\\to\\pickle.pkl&#39;
    &gt;&gt;&gt; pkl_dict = {&#34;A&#34;: np.ones([3, 3]),
                    &#34;B&#34;: datetime.today(),
                    &#34;C&#34;: SomeEnum.some_name}
    &gt;&gt;&gt; save_json(output_pkl, pkl_dict)
    ```

    Args:
        obj (Any): Any object serializable
        path (Union[str, CloudPath, Path]): Path where to write the pickle
    &#34;&#34;&#34;
    with open(path, &#34;wb+&#34;) as file:
        pickle.dump(obj, file)


def load_obj(path: Union[str, CloudPath, Path]) -&gt; Any:
    &#34;&#34;&#34;
    Load a pickled object.

    ```python
    &gt;&gt;&gt; output_pkl = &#39;D:\\path\\to\\pickle.pkl&#39;
    &gt;&gt;&gt; load_obj(output_pkl)
    {&#34;A&#34;: np.ones([3, 3]), &#34;B&#34;: datetime.today(), &#34;C&#34;: SomeEnum.some_name}
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path of the pickle
    Returns:
        object (Any): Pickled object

    &#34;&#34;&#34;
    with open(path, &#34;rb&#34;) as file:
        return pickle.load(file)


# too many arguments
# pylint: disable=R0913
def get_file_in_dir(
    directory: Union[str, CloudPath, Path],
    pattern_str: str,
    extension: str = None,
    filename_only: bool = False,
    get_list: bool = False,
    exact_name: bool = False,
) -&gt; Union[CloudPath, Path, list]:
    &#34;&#34;&#34;
    Get one or all matching files (pattern + extension) from inside a directory.

    Note that the pattern is a regex with glob&#39;s convention, ie. `*pattern*`.

    If `exact_name` is `False`, the searched pattern will be `*{pattern}*.{extension}`, else `{pattern}.{extension}`.

    ```python
    &gt;&gt;&gt; directory = &#39;D:\\path\\to\\dir&#39;
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;haha.txt&#34;, &#34;huhu1.txt&#34;, &#34;huhu1.geojson&#34;, &#34;hoho.txt&#34;]

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;)
    &#39;D:\\path\\to\\dir\\huhu1.geojson&#39;

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, extension=&#34;txt&#34;)
    &#39;D:\\path\\to\\dir\\huhu1.txt&#39;

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, get_list=True)
    [&#39;D:\\path\\to\\dir\\huhu1.txt&#39;, &#39;D:\\path\\to\\dir\\huhu1.geojson&#39;]

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, filename_only=True, get_list=True)
    [&#39;huhu1.txt&#39;, &#39;huhu1.geojson&#39;]

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, get_list=True, exact_name=True)
    []
    ```

    Args:
        directory (str): Directory where to find the files
        pattern_str (str): Pattern wanted as a string, with glob&#39;s convention.
        extension (str): Extension wanted, optional. With or without point. (`yaml` or `.yaml` accepted)
        filename_only (bool): Get only the filename
        get_list (bool): Get the whole list of matching files
        exact_name (bool): Get the exact name (without adding `*` before and after the given pattern)

    Returns:
        Union[CloudPath, Path, list]: File
    &#34;&#34;&#34;
    directory = AnyPath(directory)

    # Glob pattern
    if exact_name:
        glob_pattern = pattern_str
    else:
        glob_pattern = &#34;*&#34; + pattern_str + &#34;*&#34;
    if extension:
        if not extension.startswith(&#34;.&#34;):
            extension = &#34;.&#34; + extension
        glob_pattern += extension

    # Search for the pattern in the directory
    file_list = list(directory.glob(glob_pattern))

    if len(file_list) == 0:
        raise FileNotFoundError(
            f&#34;File with pattern {glob_pattern} not found in {directory}&#34;
        )

    # Return list, file path or file name
    if get_list:
        file = file_list
    else:
        if len(file_list) &gt; 1:
            LOGGER.warning(
                &#34;More than one file corresponding to the pattern %s has been found here %s. &#34;
                &#34;Only the first item will be returned.&#34;,
                glob_pattern,
                directory,
            )
        file = file_list[0]
        if filename_only:
            file = file.name

    return file


# pylint: disable=E1121
def hash_file_content(file_content: str, len_param: int = 5) -&gt; str:
    &#34;&#34;&#34;
    Hash a file into a unique str.

    ```python
    &gt;&gt;&gt; read_json(&#34;path\\to\\json.json&#34;)
    {&#34;A&#34;: 1, &#34;B&#34;: 2}

    &gt;&gt;&gt; hash_file_content(str(file_content))
    &#34;d3fad5bdf9&#34;
    ```

    Args:
        file_content (str): File content
        len_param (int): Length parameter for the hash (length of the key will be 2x this number)

    Returns:
        str: Hashed file content
    &#34;&#34;&#34;
    hasher = hashlib.shake_256()
    hasher.update(str.encode(file_content))
    return hasher.hexdigest(len_param)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sertit.files.get_root_path"><code class="name flex">
<p>def <span class="ident">get_root_path</span>(</p><p>)</p>
</code></dt>
<dd>
<div class="desc"><p>Get the root path of the current disk:</p>
<ul>
<li>On Linux this returns <code>/</code></li>
<li>On Windows this returns <code>C:\</code> or whatever the current drive is</li>
</ul>
<pre><code class="language-python">&gt;&gt;&gt; get_root_path()
&quot;/&quot; on Linux
&quot;C:\&quot; on Windows (if you run this code from the C: drive)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_root_path() -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Get the root path of the current disk:

    - On Linux this returns `/`
    - On Windows this returns `C:\\` or whatever the current drive is

    ```python
    &gt;&gt;&gt; get_root_path()
    &#34;/&#34; on Linux
    &#34;C:\\&#34; on Windows (if you run this code from the C: drive)
    ```
    &#34;&#34;&#34;
    return AnyPath(os.path.abspath(os.sep))</code></pre>
</details>
</dd>
<dt id="sertit.files.listdir_abspath"><code class="name flex">
<p>def <span class="ident">listdir_abspath</span>(</p><p>directory)</p>
</code></dt>
<dd>
<div class="desc"><p>Get absolute path of all files in the given directory.</p>
<p>It is the same function than <code>os.listdir</code> but returning absolute paths.</p>
<pre><code class="language-python">&gt;&gt;&gt; folder = &quot;.&quot;
&gt;&gt;&gt; listdir_abspath(folder)
['D:\_SERTIT_UTILS\sertit-utils\sertit\files.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\logs.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\misc.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\network.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\rasters_rio.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\strings.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\vectors.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\version.py',
'D:\_SERTIT_UTILS\sertit-utils\sertit\__init__.py']
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>directory</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Relative or absolute path to the directory to be scanned</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Absolute path of all files in the given directory</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def listdir_abspath(directory: Union[str, CloudPath, Path]) -&gt; list:
    &#34;&#34;&#34;
    Get absolute path of all files in the given directory.

    It is the same function than `os.listdir` but returning absolute paths.

    ```python
    &gt;&gt;&gt; folder = &#34;.&#34;
    &gt;&gt;&gt; listdir_abspath(folder)
    [&#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\files.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\logs.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\misc.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\network.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\rasters_rio.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\strings.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\vectors.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\version.py&#39;,
    &#39;D:\\_SERTIT_UTILS\\sertit-utils\\sertit\\__init__.py&#39;]
    ```

    Args:
        directory (Union[str, CloudPath, Path]): Relative or absolute path to the directory to be scanned

    Returns:
        str: Absolute path of all files in the given directory
    &#34;&#34;&#34;
    dirpath = AnyPath(directory)

    return list(dirpath.iterdir())</code></pre>
</details>
</dd>
<dt id="sertit.files.to_abspath"><code class="name flex">
<p>def <span class="ident">to_abspath</span>(</p><p>path, <br>create=True)</p>
</code></dt>
<dd>
<div class="desc"><p>Return the absolute path of the specified path and check if it exists</p>
<p>If not:</p>
<ul>
<li>If it is a file (aka has an extension), it raises an exception</li>
<li>If it is a folder, it creates it</li>
</ul>
<p>To be used with argparse to retrieve the absolute path of a file, like:</p>
<pre><code class="language-python">&gt;&gt;&gt; parser = argparse.ArgumentParser()
&gt;&gt;&gt; # Add config file path key
&gt;&gt;&gt; parser.add_argument(&quot;--config&quot;,
                        help=&quot;Config file path (absolute or relative)&quot;,
                        type=to_abspath)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Path as a string (relative or absolute)</dd>
<dt><strong><code>create</code></strong> :&ensp;<code>bool</code></dt>
<dd>Create directory if not existing</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[CloudPath, Path]</code></dt>
<dd>Absolute path</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_abspath(
    path: Union[str, CloudPath, Path], create: bool = True
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Return the absolute path of the specified path and check if it exists

    If not:

    - If it is a file (aka has an extension), it raises an exception
    - If it is a folder, it creates it

    To be used with argparse to retrieve the absolute path of a file, like:

    ```python
    &gt;&gt;&gt; parser = argparse.ArgumentParser()
    &gt;&gt;&gt; # Add config file path key
    &gt;&gt;&gt; parser.add_argument(&#34;--config&#34;,
                            help=&#34;Config file path (absolute or relative)&#34;,
                            type=to_abspath)
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path as a string (relative or absolute)
        create (bool): Create directory if not existing

    Returns:
        Union[CloudPath, Path]: Absolute path
    &#34;&#34;&#34;
    abs_path = AnyPath(path).resolve()

    if not abs_path.exists():
        if abs_path.suffix:
            # If the path specifies a file (with extension), it raises an exception
            raise FileNotFoundError(f&#34;Non existing file: {abs_path}&#34;)

        # If the path specifies a folder, it creates it
        if create:
            abs_path.mkdir()

    return abs_path</code></pre>
</details>
</dd>
<dt id="sertit.files.real_rel_path"><code class="name flex">
<p>def <span class="ident">real_rel_path</span>(</p><p>path, <br>start)</p>
</code></dt>
<dd>
<div class="desc"><p>Gives the real relative path from a starting folder.
(and not just adding <code>..\..</code> between the start and the target)</p>
<pre><code class="language-python">&gt;&gt;&gt; path = r'D:\_SERTIT_UTILS\sertit-utils\sertit'
&gt;&gt;&gt; start = os.path.join(&quot;.&quot;, &quot;..&quot;, &quot;..&quot;)
&gt;&gt;&gt; real_rel_path(path, start)
'sertit-utils\sertit'
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Path to make relative</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Start, the path being relative from this folder.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Relative path</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def real_rel_path(
    path: Union[str, CloudPath, Path], start: Union[str, CloudPath, Path]
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Gives the real relative path from a starting folder.
    (and not just adding `..\..` between the start and the target)

    ```python
    &gt;&gt;&gt; path = r&#39;D:\_SERTIT_UTILS\sertit-utils\sertit&#39;
    &gt;&gt;&gt; start = os.path.join(&#34;.&#34;, &#34;..&#34;, &#34;..&#34;)
    &gt;&gt;&gt; real_rel_path(path, start)
    &#39;sertit-utils\\sertit&#39;
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path to make relative
        start (Union[str, CloudPath, Path]): Start, the path being relative from this folder.

    Returns:
        Relative path
    &#34;&#34;&#34;
    path = AnyPath(path)
    start = AnyPath(start)
    rel_path = path
    if not isinstance(path, CloudPath) and not isinstance(start, CloudPath):
        rel_path = path.resolve().relative_to(start.resolve())

    return rel_path</code></pre>
</details>
</dd>
<dt id="sertit.files.extract_file"><code class="name flex">
<p>def <span class="ident">extract_file</span>(</p><p>file_path, <br>output, <br>overwrite=False)</p>
</code></dt>
<dd>
<div class="desc"><p>Extract an archived file (zip or others). Overwrites if specified.
For zipfiles, in case of multiple folders archived, pay attention that what is returned is the first folder.</p>
<pre><code class="language-python">&gt;&gt;&gt; file_path = 'D:\path\to\zip.zip'
&gt;&gt;&gt; output = 'D:\path\to\output'
&gt;&gt;&gt; extract_file(file_path, output, overwrite=True)
D:\path\to\output\zip'
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Archive file path</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>str</code></dt>
<dd>Output where to put the extracted file</dd>
<dt><strong><code>overwrite</code></strong> :&ensp;<code>bool</code></dt>
<dd>Overwrite found extracted files</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[list, CloudPath, Path]</code></dt>
<dd>Extracted file paths (as str if only one)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_file(
    file_path: Union[str, CloudPath, Path],
    output: Union[str, CloudPath, Path],
    overwrite: bool = False,
) -&gt; Union[list, CloudPath, Path]:
    &#34;&#34;&#34;
    Extract an archived file (zip or others). Overwrites if specified.
    For zipfiles, in case of multiple folders archived, pay attention that what is returned is the first folder.

    ```python
    &gt;&gt;&gt; file_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; output = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; extract_file(file_path, output, overwrite=True)
    D:\\path\\to\\output\zip&#39;
    ```

    Args:
        file_path (str): Archive file path
        output (str): Output where to put the extracted file
        overwrite (bool): Overwrite found extracted files

    Returns:
        Union[list, CloudPath, Path]: Extracted file paths (as str if only one)
    &#34;&#34;&#34;
    # Convert to path
    file_path = AnyPath(file_path)
    output = AnyPath(output)

    # In case a folder is given, returns it (this means that the file is already extracted)
    if file_path.is_dir():
        return file_path

    # Manage archive type
    if file_path.suffix == &#34;.zip&#34;:
        # Manage the case with several directories inside one zipfile
        arch = zipfile.ZipFile(file_path, &#34;r&#34;)
        extr_names = list({path.split(&#34;/&#34;)[0] for path in arch.namelist()})
    elif file_path.suffix == &#34;.tar&#34; or file_path.suffixes == [&#34;.tar&#34;, &#34;.gz&#34;]:
        # Tar files have no subdirectories, so create one
        extr_names = [get_filename(file_path)]
        arch = tarfile.open(file_path, &#34;r&#34;)
    else:
        raise TypeError(
            f&#34;Only .zip, .tar and .tar.gz files can be extracted, not {file_path}&#34;
        )

    # Get extracted list
    extr_dirs = [output.joinpath(extr_name) for extr_name in extr_names]

    # Loop over basedirs from inside the archive
    for extr_dir in extr_dirs:
        extr_name = extr_dir.name
        # Manage overwriting
        if extr_dir.is_dir():
            if overwrite:
                LOGGER.debug(
                    &#34;Already existing extracted %s. It will be overwritten as asked.&#34;,
                    extr_names,
                )
                remove(extr_dir)
            else:
                LOGGER.debug(
                    &#34;Already existing extracted %s. It won&#39;t be overwritten.&#34;,
                    extr_names,
                )

        else:
            LOGGER.info(&#34;Extracting %s&#34;, extr_names)
            # Inside docker, extracting files is really slow -&gt; copy the archive in a tmp directory
            with tempfile.TemporaryDirectory() as tmp_dir:
                if misc.in_docker():
                    # Create a tmp directory
                    copy(file_path, tmp_dir)
                    file_path = os.path.join(tmp_dir, os.path.basename(file_path))
                    tmp_extr_output = tmp_dir

                    # Recreate dir with tmp output
                    tmp_extr_dir = os.path.join(tmp_extr_output, extr_name)
                else:
                    tmp_extr_output = output
                    tmp_extr_dir = extr_dir

                if str(file_path).endswith(&#34;.zip&#34;):
                    members = [name for name in arch.namelist() if extr_name in name]
                else:
                    members = arch.getmembers()  # Always extract all files for TAR data

                    # Tar files do not contain a file tree
                    tmp_extr_output = tmp_extr_dir

                # Extract product
                try:
                    os.makedirs(tmp_extr_dir, exist_ok=True)
                    arch.extractall(path=tmp_extr_output, members=members)
                except tarfile.ReadError as ex:
                    raise TypeError(f&#34;Impossible to extract {file_path}&#34;) from ex

                # Copy back if we are running inside docker and clean tmp dir
                if misc.in_docker():
                    copy(tmp_extr_dir, extr_dir)

    # Close archive
    arch.close()

    # Return str for compatibility reasons
    if len(extr_dirs) == 1:
        extr_dirs = extr_dirs[0]

    return extr_dirs</code></pre>
</details>
</dd>
<dt id="sertit.files.extract_files"><code class="name flex">
<p>def <span class="ident">extract_files</span>(</p><p>archives, <br>output, <br>overwrite=False)</p>
</code></dt>
<dd>
<div class="desc"><p>Extract all archived files. Overwrites if specified.</p>
<pre><code class="language-python">&gt;&gt;&gt; file_path = ['D:\path\to\zip1.zip', 'D:\path\to\zip2.zip']
&gt;&gt;&gt; output = 'D:\path\to\output'
&gt;&gt;&gt; extract_files(file_path, output, overwrite=True)
['D:\path\to\output\zip1', 'D:\path\to\output\zip2']
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>archives</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>List of archives to be extracted</dd>
<dt><strong><code>output</code></strong> :&ensp;<code>str</code></dt>
<dd>Output folder where extracted files will be written</dd>
<dt><strong><code>overwrite</code></strong> :&ensp;<code>bool</code></dt>
<dd>Overwrite found extracted files</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>Extracted files (even pre-existing ones)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_files(
    archives: list, output: Union[str, CloudPath, Path], overwrite: bool = False
) -&gt; list:
    &#34;&#34;&#34;
    Extract all archived files. Overwrites if specified.

    ```python
    &gt;&gt;&gt; file_path = [&#39;D:\\path\\to\\zip1.zip&#39;, &#39;D:\\path\\to\\zip2.zip&#39;]
    &gt;&gt;&gt; output = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; extract_files(file_path, output, overwrite=True)
    [&#39;D:\\path\\to\\output\zip1&#39;, &#39;D:\\path\\to\\output\zip2&#39;]
    ```

    Args:
        archives (list of str): List of archives to be extracted
        output (str): Output folder where extracted files will be written
        overwrite (bool): Overwrite found extracted files

    Returns:
        list: Extracted files (even pre-existing ones)
    &#34;&#34;&#34;
    LOGGER.info(&#34;Extracting products in %s&#34;, output)
    progress_bar = tqdm(archives)
    extracts = []
    for arch in progress_bar:
        progress_bar.set_description(f&#34;Extracting product {os.path.basename(arch)}&#34;)
        extracts.append(extract_file(arch, output, overwrite))

    return extracts</code></pre>
</details>
</dd>
<dt id="sertit.files.get_archived_file_list"><code class="name flex">
<p>def <span class="ident">get_archived_file_list</span>(</p><p>archive_path)</p>
</code></dt>
<dd>
<div class="desc"><p>Get the list of all the files contained in an archive.</p>
<pre><code class="language-python">&gt;&gt;&gt; arch_path = 'D:\path\to\zip.zip'
&gt;&gt;&gt; get_archived_file_list(arch_path, file_regex)
['file_1.txt', 'file_2.tif', 'file_3.xml', 'file_4.geojson']
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>archive_path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Archive path</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>All files contained in the given archive</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_archived_file_list(archive_path: Union[str, CloudPath, Path]) -&gt; list:
    &#34;&#34;&#34;
    Get the list of all the files contained in an archive.

    ```python
    &gt;&gt;&gt; arch_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; get_archived_file_list(arch_path, file_regex)
    [&#39;file_1.txt&#39;, &#39;file_2.tif&#39;, &#39;file_3.xml&#39;, &#39;file_4.geojson&#39;]
    ```

    Args:
        archive_path (Union[str, CloudPath, Path]): Archive path

    Returns:
        list: All files contained in the given archive
    &#34;&#34;&#34;
    archive_path = AnyPath(archive_path)
    if archive_path.suffix == &#34;.zip&#34;:
        with zipfile.ZipFile(archive_path) as zip_ds:
            file_list = [f.filename for f in zip_ds.filelist]
    else:
        try:
            with tarfile.open(archive_path) as tar_ds:
                tar_mb = tar_ds.getmembers()
                file_list = [mb.name for mb in tar_mb]
        except tarfile.ReadError as ex:
            raise TypeError(f&#34;Impossible to open archive: {archive_path}&#34;) from ex

    return file_list</code></pre>
</details>
</dd>
<dt id="sertit.files.get_archived_rio_path"><code class="name flex">
<p>def <span class="ident">get_archived_rio_path</span>(</p><p>archive_path, <br>file_regex, <br>as_list=False)</p>
</code></dt>
<dd>
<div class="desc"><p>Get archived file path from inside the archive, to be read with rasterio:</p>
<ul>
<li><code>zip+file://{zip_path}!{file_name}</code></li>
<li><code>tar+file://{tar_path}!{file_name}</code></li>
</ul>
<p>See <a href="https://rasterio.readthedocs.io/en/latest/topics/datasets.html?highlight=zip#dataset-identifiers">here</a>
for more information.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It wont be readable by pandas, geopandas or xmltree !</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code>as_list</code> is <code>False</code>, it will only return the first file matched !</p>
</div>
<p>You can use this <a href="https://regexr.com/">site</a> to build your regex.</p>
<pre><code class="language-python">&gt;&gt;&gt; arch_path = 'D:\path\to\zip.zip'
&gt;&gt;&gt; file_regex = '.*dir.*file_name'  # Use .* for any character
&gt;&gt;&gt; path = get_archived_tif_path(arch_path, file_regex)
'zip+file://D:\path\to\output\zip!dir/filename.tif'
&gt;&gt;&gt; rasterio.open(path)
&lt;open DatasetReader name='zip+file://D:\path\to\output\zip!dir/filename.tif' mode='r'&gt;
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>archive_path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Archive path</dd>
<dt><strong><code>file_regex</code></strong> :&ensp;<code>str</code></dt>
<dd>File regex (used by re) as it can be found in the getmembers() list</dd>
<dt><strong><code>as_list</code></strong> :&ensp;<code>bool</code></dt>
<dd>If true, returns a list (including all found files). If false, returns only the first match</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[list, str]</code></dt>
<dd>Band path that can be read by rasterio</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_archived_rio_path(
    archive_path: Union[str, CloudPath, Path], file_regex: str, as_list: bool = False
) -&gt; Union[list, CloudPath, Path]:
    &#34;&#34;&#34;
    Get archived file path from inside the archive, to be read with rasterio:

    - `zip+file://{zip_path}!{file_name}`
    - `tar+file://{tar_path}!{file_name}`

    See [here](https://rasterio.readthedocs.io/en/latest/topics/datasets.html?highlight=zip#dataset-identifiers)
    for more information.

    .. WARNING::
        It wont be readable by pandas, geopandas or xmltree !

    .. WARNING::
        If `as_list` is `False`, it will only return the first file matched !

    You can use this [site](https://regexr.com/) to build your regex.

    ```python
    &gt;&gt;&gt; arch_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; file_regex = &#39;.*dir.*file_name&#39;  # Use .* for any character
    &gt;&gt;&gt; path = get_archived_tif_path(arch_path, file_regex)
    &#39;zip+file://D:\\path\\to\\output\zip!dir/filename.tif&#39;
    &gt;&gt;&gt; rasterio.open(path)
    &lt;open DatasetReader name=&#39;zip+file://D:\\path\\to\\output\zip!dir/filename.tif&#39; mode=&#39;r&#39;&gt;
    ```

    Args:
        archive_path (Union[str, CloudPath, Path]): Archive path
        file_regex (str): File regex (used by re) as it can be found in the getmembers() list
        as_list (bool): If true, returns a list (including all found files). If false, returns only the first match

    Returns:
        Union[list, str]: Band path that can be read by rasterio
    &#34;&#34;&#34;
    # Get file list
    archive_path = AnyPath(archive_path)
    file_list = get_archived_file_list(archive_path)

    if archive_path.suffix in [&#34;.tar&#34;, &#34;.zip&#34;]:
        prefix = archive_path.suffix[-3:]
    elif archive_path.suffix == &#34;.tar.gz&#34;:
        raise TypeError(
            &#34;.tar.gz files are too slow to be read from inside the archive. Please extract them instead.&#34;
        )
    else:
        raise TypeError(&#34;Only .zip and .tar files can be read from inside its archive.&#34;)

    # Search for file
    regex = re.compile(file_regex)
    archived_band_path = list(filter(regex.match, file_list))
    if not archived_band_path:
        raise FileNotFoundError(
            f&#34;Impossible to find file {file_regex} in {get_filename(archive_path)}&#34;
        )

    # Convert to rio path
    if isinstance(archive_path, CloudPath):
        archived_band_path = [
            f&#34;{prefix}+file+{archive_path}!{path}&#34; for path in archived_band_path
        ]
    else:
        archived_band_path = [
            f&#34;{prefix}+file://{archive_path}!{path}&#34; for path in archived_band_path
        ]

    # Convert to str if needed
    if not as_list:
        archived_band_path = archived_band_path[0]

    return archived_band_path</code></pre>
</details>
</dd>
<dt id="sertit.files.read_archived_xml"><code class="name flex">
<p>def <span class="ident">read_archived_xml</span>(</p><p>archive_path, <br>xml_regex)</p>
</code></dt>
<dd>
<div class="desc"><p>Read archived XML from <code>zip</code> or <code>tar</code> archives.</p>
<p>You can use this <a href="https://regexr.com/">site</a> to build your regex.</p>
<pre><code class="language-python">&gt;&gt;&gt; arch_path = 'D:\path\to\zip.zip'
&gt;&gt;&gt; file_regex = '.*dir.*file_name'  # Use .* for any character
&gt;&gt;&gt; read_archived_xml(arch_path, file_regex)
&lt;Element LANDSAT_METADATA_FILE at 0x1c90007f8c8&gt;
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>archive_path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Archive path</dd>
<dt><strong><code>xml_regex</code></strong> :&ensp;<code>str</code></dt>
<dd>XML regex (used by re) as it can be found in the getmembers() list</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>etree._Element</code></dt>
<dd>XML file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_archived_xml(
    archive_path: Union[str, CloudPath, Path], xml_regex: str
) -&gt; etree._Element:
    &#34;&#34;&#34;
    Read archived XML from `zip` or `tar` archives.

    You can use this [site](https://regexr.com/) to build your regex.

    ```python
    &gt;&gt;&gt; arch_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; file_regex = &#39;.*dir.*file_name&#39;  # Use .* for any character
    &gt;&gt;&gt; read_archived_xml(arch_path, file_regex)
    &lt;Element LANDSAT_METADATA_FILE at 0x1c90007f8c8&gt;
    ```

    Args:
        archive_path (Union[str, CloudPath, Path]): Archive path
        xml_regex (str): XML regex (used by re) as it can be found in the getmembers() list

    Returns:
         etree._Element: XML file
    &#34;&#34;&#34;
    archive_path = AnyPath(archive_path)

    # Compile regex
    regex = re.compile(xml_regex)

    # Open tar and zip XML
    try:
        if archive_path.suffix == &#34;.tar&#34;:
            with tarfile.open(archive_path) as tar_ds:
                tar_mb = tar_ds.getmembers()
                name_list = [mb.name for mb in tar_mb]
                band_name = list(filter(regex.match, name_list))[0]
                tarinfo = [mb for mb in tar_mb if mb.name == band_name][0]
                xml_str = tar_ds.extractfile(tarinfo).read()
        elif archive_path.suffix == &#34;.zip&#34;:
            with zipfile.ZipFile(archive_path) as zip_ds:
                name_list = [f.filename for f in zip_ds.filelist]
                band_name = list(filter(regex.match, name_list))[0]
                xml_str = zip_ds.read(band_name)

        elif archive_path.suffix == &#34;.tar.gz&#34;:
            raise TypeError(
                &#34;.tar.gz files are too slow to read from inside the archive. Please extract them instead.&#34;
            )
        else:
            raise TypeError(
                &#34;Only .zip and .tar files can be read from inside its archive.&#34;
            )
    except IndexError:
        raise FileNotFoundError(
            f&#34;Impossible to find XML file {xml_regex} in {get_filename(archive_path)}&#34;
        )

    return etree.fromstring(xml_str)</code></pre>
</details>
</dd>
<dt id="sertit.files.archive"><code class="name flex">
<p>def <span class="ident">archive</span>(</p><p>folder_path, <br>archive_path, <br>fmt='zip')</p>
</code></dt>
<dd>
<div class="desc"><p>Archives a folder recursively.</p>
<pre><code class="language-python">&gt;&gt;&gt; folder_path = 'D:\path\to\folder_to_archive'
&gt;&gt;&gt; archive_path = 'D:\path\to\output'
&gt;&gt;&gt; archive = archive(folder_path, archive_path, fmt=&quot;gztar&quot;)
'D:\path\to\output\folder_to_archive.tar.gz'
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>folder_path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Folder to archive</dd>
<dt><strong><code>archive_path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Archive path, with or without extension</dd>
<dt><strong><code>fmt</code></strong> :&ensp;<code>str</code></dt>
<dd>Format of the archive, used by <code>shutil.make_archive</code>. Choose between [zip, tar, gztar, bztar, xztar]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Archive filename</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def archive(
    folder_path: Union[str, CloudPath, Path],
    archive_path: Union[str, CloudPath, Path],
    fmt: str = &#34;zip&#34;,
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Archives a folder recursively.

    ```python
    &gt;&gt;&gt; folder_path = &#39;D:\\path\\to\\folder_to_archive&#39;
    &gt;&gt;&gt; archive_path = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; archive = archive(folder_path, archive_path, fmt=&#34;gztar&#34;)
    &#39;D:\\path\\to\\output\\folder_to_archive.tar.gz&#39;
    ```

    Args:
        folder_path (Union[str, CloudPath, Path]): Folder to archive
        archive_path (Union[str, CloudPath, Path]): Archive path, with or without extension
        fmt (str): Format of the archive, used by `shutil.make_archive`. Choose between [zip, tar, gztar, bztar, xztar]
    Returns:
        str: Archive filename
    &#34;&#34;&#34;
    archive_path = AnyPath(archive_path)
    folder_path = AnyPath(folder_path)

    # Shutil make_archive needs a path without extension
    archive_base = os.path.splitext(archive_path)[0]

    # Archive the folder
    archive_fn = shutil.make_archive(
        archive_base,
        format=fmt,
        root_dir=folder_path.parent,
        base_dir=folder_path.name,
    )

    return AnyPath(archive_fn)</code></pre>
</details>
</dd>
<dt id="sertit.files.add_to_zip"><code class="name flex">
<p>def <span class="ident">add_to_zip</span>(</p><p>zip_path, <br>dirs_to_add)</p>
</code></dt>
<dd>
<div class="desc"><p>Add folders to an already existing zip file (recursively).</p>
<pre><code class="language-python">&gt;&gt;&gt; zip_path = 'D:\path\to\zip.zip'
&gt;&gt;&gt; dirs_to_add = ['D:\path\to\dir1', 'D:\path\to\dir2']
&gt;&gt;&gt; add_to_zip(zip_path, dirs_to_add)
&gt;&gt;&gt; # zip.zip contains 2 more folders, dir1 and dir2
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>zip_path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Already existing zip file</dd>
<dt><strong><code>dirs_to_add</code></strong> :&ensp;<code>Union[list, str]</code></dt>
<dd>Directories to add</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_to_zip(
    zip_path: Union[str, CloudPath, Path],
    dirs_to_add: Union[list, str, CloudPath, Path],
) -&gt; None:
    &#34;&#34;&#34;
    Add folders to an already existing zip file (recursively).

    ```python
    &gt;&gt;&gt; zip_path = &#39;D:\\path\\to\\zip.zip&#39;
    &gt;&gt;&gt; dirs_to_add = [&#39;D:\\path\\to\\dir1&#39;, &#39;D:\\path\\to\\dir2&#39;]
    &gt;&gt;&gt; add_to_zip(zip_path, dirs_to_add)
    &gt;&gt;&gt; # zip.zip contains 2 more folders, dir1 and dir2
    ```

    Args:
        zip_path (Union[str, CloudPath, Path]): Already existing zip file
        dirs_to_add (Union[list, str]): Directories to add
    &#34;&#34;&#34;
    zip_path = AnyPath(zip_path)

    # Check if existing zipfile
    if not zip_path.is_file():
        raise FileNotFoundError(f&#34;Non existing {zip_path}&#34;)

    # Convert to list if needed
    if not isinstance(dirs_to_add, list):
        dirs_to_add = [dirs_to_add]

    # Add all folders to the existing zip
    # Forced to use ZipFile because make_archive only works with one folder and not existing zipfile
    with zipfile.ZipFile(zip_path, &#34;a&#34;) as zip_file:
        progress_bar = tqdm(dirs_to_add)
        for dir_to_add in progress_bar:
            progress_bar.set_description(
                f&#34;Adding {os.path.basename(dir_to_add)} to {os.path.basename(zip_path)}&#34;
            )
            for root, _, files in os.walk(dir_to_add):
                base_path = os.path.join(dir_to_add, &#34;..&#34;)

                # Write dir (in namelist at least)
                zip_file.write(root, os.path.relpath(root, base_path))

                # Write files
                for file in files:
                    zip_file.write(
                        os.path.join(root, file),
                        os.path.relpath(
                            os.path.join(root, file), os.path.join(dir_to_add, &#34;..&#34;)
                        ),
                    )</code></pre>
</details>
</dd>
<dt id="sertit.files.get_filename"><code class="name flex">
<p>def <span class="ident">get_filename</span>(</p><p>file_path)</p>
</code></dt>
<dd>
<div class="desc"><p>Get file name (without extension) from file path, ie:</p>
<pre><code class="language-python">&gt;&gt;&gt; file_path = 'D:\path\to\filename.zip'
&gt;&gt;&gt; get_file_name(file_path)
'filename'
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Absolute or relative file path (the file doesn't need to exist)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>File name (without extension)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_filename(file_path: Union[str, CloudPath, Path]) -&gt; str:
    &#34;&#34;&#34;
    Get file name (without extension) from file path, ie:

    ```python
    &gt;&gt;&gt; file_path = &#39;D:\\path\\to\\filename.zip&#39;
    &gt;&gt;&gt; get_file_name(file_path)
    &#39;filename&#39;
    ```

    Args:
        file_path (Union[str, CloudPath, Path]): Absolute or relative file path (the file doesn&#39;t need to exist)

    Returns:
        str: File name (without extension)
    &#34;&#34;&#34;
    file_path = AnyPath(file_path)

    # We need to avoid splitext because of nested extensions such as .tar.gz
    return file_path.name.split(&#34;.&#34;)[0]</code></pre>
</details>
</dd>
<dt id="sertit.files.remove"><code class="name flex">
<p>def <span class="ident">remove</span>(</p><p>path)</p>
</code></dt>
<dd>
<div class="desc"><p>Deletes a file or a directory (recursively) using <code>shutil.rmtree</code> or <code>os.remove</code>.</p>
<pre><code class="language-python">&gt;&gt;&gt; path_to_remove = 'D:\path\to\remove'  # Could also be a file
&gt;&gt;&gt; remove(path_to_remove)
path_to_remove deleted
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Path to be removed</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove(path: Union[str, CloudPath, Path]) -&gt; None:
    &#34;&#34;&#34;
    Deletes a file or a directory (recursively) using `shutil.rmtree` or `os.remove`.

    ```python
    &gt;&gt;&gt; path_to_remove = &#39;D:\\path\\to\\remove&#39;  # Could also be a file
    &gt;&gt;&gt; remove(path_to_remove)
    path_to_remove deleted
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path to be removed
    &#34;&#34;&#34;
    path = AnyPath(path)
    if not path.exists():
        LOGGER.debug(&#34;Non existing %s&#34;, path)

    elif path.is_dir():
        try:
            shutil.rmtree(path)
        except OSError:
            LOGGER.debug(&#34;Impossible to remove the directory %s&#34;, path, exc_info=True)

    elif path.is_file():
        try:
            path.unlink()
        except OSError:
            LOGGER.debug(&#34;Impossible to remove the file %s&#34;, path, exc_info=True)</code></pre>
</details>
</dd>
<dt id="sertit.files.remove_by_pattern"><code class="name flex">
<p>def <span class="ident">remove_by_pattern</span>(</p><p>directory, <br>name_with_wildcard='*', <br>extension=None)</p>
</code></dt>
<dd>
<div class="desc"><p>Remove files corresponding to a pattern from a directory.</p>
<pre><code class="language-python">&gt;&gt;&gt; directory = 'D:\path\to\folder'
&gt;&gt;&gt; os.listdir(directory)
[&quot;huhu.exe&quot;, &quot;blabla.geojson&quot;, &quot;haha.txt&quot;, &quot;blabla&quot;]

&gt;&gt;&gt; remove(directory, &quot;blabla*&quot;)
&gt;&gt;&gt; os.listdir(directory)
[&quot;huhu.exe&quot;, &quot;haha.txt&quot;] # Removes also directories

&gt;&gt;&gt; remove(directory, &quot;*&quot;, extension=&quot;txt&quot;)
&gt;&gt;&gt; os.listdir(directory)
[&quot;huhu.exe&quot;]
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>directory</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Directory where to find the files</dd>
<dt><strong><code>name_with_wildcard</code></strong> :&ensp;<code>str</code></dt>
<dd>Filename (wildcards accepted)</dd>
<dt><strong><code>extension</code></strong> :&ensp;<code>str</code></dt>
<dd>Extension wanted, optional. With or without point. (yaml or .yaml accepted)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_by_pattern(
    directory: Union[str, CloudPath, Path],
    name_with_wildcard: str = &#34;*&#34;,
    extension: str = None,
) -&gt; None:
    &#34;&#34;&#34;
    Remove files corresponding to a pattern from a directory.

    ```python
    &gt;&gt;&gt; directory = &#39;D:\\path\\to\\folder&#39;
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;huhu.exe&#34;, &#34;blabla.geojson&#34;, &#34;haha.txt&#34;, &#34;blabla&#34;]

    &gt;&gt;&gt; remove(directory, &#34;blabla*&#34;)
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;huhu.exe&#34;, &#34;haha.txt&#34;] # Removes also directories

    &gt;&gt;&gt; remove(directory, &#34;*&#34;, extension=&#34;txt&#34;)
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;huhu.exe&#34;]
    ```

    Args:
        directory (Union[str, CloudPath, Path]): Directory where to find the files
        name_with_wildcard (str): Filename (wildcards accepted)
        extension (str): Extension wanted, optional. With or without point. (yaml or .yaml accepted)
    &#34;&#34;&#34;
    directory = AnyPath(directory)
    if extension and not extension.startswith(&#34;.&#34;):
        extension = &#34;.&#34; + extension

    file_list = directory.glob(name_with_wildcard + extension)
    for file in file_list:
        remove(file)</code></pre>
</details>
</dd>
<dt id="sertit.files.copy"><code class="name flex">
<p>def <span class="ident">copy</span>(</p><p>src, <br>dst)</p>
</code></dt>
<dd>
<div class="desc"><p>Copy a file or a directory (recursively) with <code>copytree</code> or <code>copy2</code>.</p>
<pre><code class="language-python">&gt;&gt;&gt; src = 'D:\path\to\copy'
&gt;&gt;&gt; dst = 'D:\path\to\output'
&gt;&gt;&gt; copy(src, dst)
copydir 'D:\path\to\output\copy'

&gt;&gt;&gt; src = 'D:\path\to\copy.txt'
&gt;&gt;&gt; dst = 'D:\path\to\output\huhu.txt'
&gt;&gt;&gt; copyfile = copy(src, dst)
'D:\path\to\output\huhu.txt' but with the content of copy.txt
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>src</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Source Path</dd>
<dt><strong><code>dst</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Destination Path (file or folder)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[CloudPath, Path]</code></dt>
<dd>New path</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(
    src: Union[str, CloudPath, Path], dst: Union[str, CloudPath, Path]
) -&gt; Union[CloudPath, Path]:
    &#34;&#34;&#34;
    Copy a file or a directory (recursively) with `copytree` or `copy2`.

    ```python
    &gt;&gt;&gt; src = &#39;D:\\path\\to\\copy&#39;
    &gt;&gt;&gt; dst = &#39;D:\\path\\to\\output&#39;
    &gt;&gt;&gt; copy(src, dst)
    copydir &#39;D:\\path\\to\\output\\copy&#39;

    &gt;&gt;&gt; src = &#39;D:\\path\\to\\copy.txt&#39;
    &gt;&gt;&gt; dst = &#39;D:\\path\\to\\output\\huhu.txt&#39;
    &gt;&gt;&gt; copyfile = copy(src, dst)
    &#39;D:\\path\\to\\output\\huhu.txt&#39; but with the content of copy.txt
    ```

    Args:
        src (Union[str, CloudPath, Path]): Source Path
        dst (Union[str, CloudPath, Path]): Destination Path (file or folder)

    Returns:
        Union[CloudPath, Path]: New path
    &#34;&#34;&#34;
    src = AnyPath(src)
    out = None
    try:
        if src.is_dir():
            out = AnyPath(shutil.copytree(src, dst))
        elif os.path.isfile(src):
            out = AnyPath(shutil.copy2(src, dst))
    except shutil.Error:
        LOGGER.debug(exc_info=True)
        out = src
        # eg. source or destination doesn&#39;t exist
    except IOError as ex:
        raise IOError(f&#34;Copy error: {ex.strerror}&#34;) from ex

    return out</code></pre>
</details>
</dd>
<dt id="sertit.files.find_files"><code class="name flex">
<p>def <span class="ident">find_files</span>(</p><p>names, <br>root_paths, <br>max_nof_files=-1, <br>get_as_str=False)</p>
</code></dt>
<dd>
<div class="desc"><p>Returns matching files recursively from a list of root paths.</p>
<p>Regex are allowed (using glob)</p>
<pre><code class="language-python">&gt;&gt;&gt; root_path = 'D:\root'
&gt;&gt;&gt; dir1_path = 'D:\root\dir1'
&gt;&gt;&gt; dir2_path = 'D:\root\dir2'

&gt;&gt;&gt; os.listdir(dir1_path)
[&quot;haha.txt&quot;, &quot;huhu.txt&quot;, &quot;hoho.txt&quot;]
&gt;&gt;&gt; os.listdir(dir2_path)
[&quot;huhu.txt&quot;, &quot;hehe.txt&quot;]

&gt;&gt;&gt; find_files(&quot;huhu.txt&quot;, root_path)
['D:\root\dir1\huhu.txt', 'D:\root\dir2\huhu.txt']

&gt;&gt;&gt; find_files(&quot;huhu.txt&quot;, root_path, max_nof_files=1)
['D:\root\dir1\huhu.txt']

&gt;&gt;&gt; find_files(&quot;huhu.txt&quot;, root_path, max_nof_files=1, get_as_str=True)
found = 'D:\root\dir1\huhu.txt'
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>names</code></strong> :&ensp;<code>Union[list, str]</code></dt>
<dd>File names.</dd>
<dt><strong><code>root_paths</code></strong> :&ensp;<code>Union[list, str]</code></dt>
<dd>Root paths</dd>
<dt><strong><code>max_nof_files</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of files (set to -1 for unlimited)</dd>
<dt><strong><code>get_as_str</code></strong> :&ensp;<code>bool</code></dt>
<dd>if only one file is found, it can be retrieved as a string instead of a list</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>File name</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_files(
    names: Union[list, str],
    root_paths: Union[list, str, CloudPath, Path],
    max_nof_files: int = -1,
    get_as_str: bool = False,
) -&gt; Union[list, str]:
    &#34;&#34;&#34;
    Returns matching files recursively from a list of root paths.

    Regex are allowed (using glob)

    ```python
    &gt;&gt;&gt; root_path = &#39;D:\\root&#39;
    &gt;&gt;&gt; dir1_path = &#39;D:\\root\\dir1&#39;
    &gt;&gt;&gt; dir2_path = &#39;D:\\root\\dir2&#39;

    &gt;&gt;&gt; os.listdir(dir1_path)
    [&#34;haha.txt&#34;, &#34;huhu.txt&#34;, &#34;hoho.txt&#34;]
    &gt;&gt;&gt; os.listdir(dir2_path)
    [&#34;huhu.txt&#34;, &#34;hehe.txt&#34;]

    &gt;&gt;&gt; find_files(&#34;huhu.txt&#34;, root_path)
    [&#39;D:\\root\\dir1\\huhu.txt&#39;, &#39;D:\\root\\dir2\\huhu.txt&#39;]

    &gt;&gt;&gt; find_files(&#34;huhu.txt&#34;, root_path, max_nof_files=1)
    [&#39;D:\\root\\dir1\\huhu.txt&#39;]

    &gt;&gt;&gt; find_files(&#34;huhu.txt&#34;, root_path, max_nof_files=1, get_as_str=True)
    found = &#39;D:\\root\\dir1\\huhu.txt&#39;
    ```

    Args:
        names (Union[list, str]): File names.
        root_paths (Union[list, str]): Root paths
        max_nof_files (int): Maximum number of files (set to -1 for unlimited)
        get_as_str (bool): if only one file is found, it can be retrieved as a string instead of a list

    Returns:
        list: File name
    &#34;&#34;&#34;
    paths = []

    # Transform to list
    if not isinstance(names, list):
        names = [names]

    if not isinstance(root_paths, list):
        root_paths = [root_paths]

    try:
        for root_path in root_paths:
            root_path = AnyPath(root_path)
            for name in names:
                paths += list(root_path.glob(f&#34;**/*{name}*&#34;))

    except StopIteration:
        pass

    # Check if found
    if not paths:
        raise FileNotFoundError(f&#34;Files {names} not found in {root_paths}&#34;)

    if max_nof_files &gt; 0:
        paths = paths[:max_nof_files]

    LOGGER.debug(
        &#34;Paths found in %s for filenames %s:\n%s&#34;,
        root_paths,
        names,
        pprint.pformat(paths),
    )

    # Get str if needed
    if len(paths) == 1 and get_as_str:
        paths = paths[0]

    return paths</code></pre>
</details>
</dd>
<dt id="sertit.files.read_json"><code class="name flex">
<p>def <span class="ident">read_json</span>(</p><p>json_file, <br>print_file=True)</p>
</code></dt>
<dd>
<div class="desc"><p>Read a JSON file</p>
<pre><code class="language-python">&gt;&gt;&gt; json_path = 'D:\path\to\json.json'
&gt;&gt;&gt; read_json(json_path, print_file=False)
{&quot;A&quot;: 1, &quot;B&quot;: 2}
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>json_file</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Path to JSON file</dd>
<dt><strong><code>print_file</code></strong> :&ensp;<code>bool</code></dt>
<dd>Print the configuration file</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>JSON data</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_json(json_file: Union[str, CloudPath, Path], print_file: bool = True) -&gt; dict:
    &#34;&#34;&#34;
    Read a JSON file

    ```python
    &gt;&gt;&gt; json_path = &#39;D:\\path\\to\\json.json&#39;
    &gt;&gt;&gt; read_json(json_path, print_file=False)
    {&#34;A&#34;: 1, &#34;B&#34;: 2}
    ```

    Args:
        json_file (Union[str, CloudPath, Path]): Path to JSON file
        print_file (bool):  Print the configuration file

    Returns:
        dict: JSON data
    &#34;&#34;&#34;

    with open(json_file) as file:
        data = json.load(file, cls=CustomDecoder)
        if print_file:
            LOGGER.debug(
                &#34;Configuration file %s contains:\n%s&#34;,
                json_file,
                json.dumps(data, indent=3, cls=CustomEncoder),
            )
    return data</code></pre>
</details>
</dd>
<dt id="sertit.files.save_json"><code class="name flex">
<p>def <span class="ident">save_json</span>(</p><p>output_json, <br>json_dict)</p>
</code></dt>
<dd>
<div class="desc"><p>Save a JSON file, with datetime, numpy types and Enum management.</p>
<pre><code class="language-python">&gt;&gt;&gt; output_json = 'D:\path\to\json.json'
&gt;&gt;&gt; json_dict = {&quot;A&quot;: np.int64(1), &quot;B&quot;: datetime.today(), &quot;C&quot;: SomeEnum.some_name}
&gt;&gt;&gt; save_json(output_json, json_dict)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_json</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Output file</dd>
<dt><strong><code>json_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Json dictionary</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_json(output_json: Union[str, CloudPath, Path], json_dict: dict) -&gt; None:
    &#34;&#34;&#34;
    Save a JSON file, with datetime, numpy types and Enum management.

    ```python
    &gt;&gt;&gt; output_json = &#39;D:\\path\\to\\json.json&#39;
    &gt;&gt;&gt; json_dict = {&#34;A&#34;: np.int64(1), &#34;B&#34;: datetime.today(), &#34;C&#34;: SomeEnum.some_name}
    &gt;&gt;&gt; save_json(output_json, json_dict)
    ```

    Args:
        output_json (Union[str, CloudPath, Path]): Output file
        json_dict (dict): Json dictionary
    &#34;&#34;&#34;

    with open(output_json, &#34;w&#34;) as output_config_file:
        json.dump(json_dict, output_config_file, indent=3, cls=CustomEncoder)</code></pre>
</details>
</dd>
<dt id="sertit.files.save_obj"><code class="name flex">
<p>def <span class="ident">save_obj</span>(</p><p>obj, <br>path)</p>
</code></dt>
<dd>
<div class="desc"><p>Save an object as a pickle (can save any Python objects).</p>
<pre><code class="language-python">&gt;&gt;&gt; output_pkl = 'D:\path\to\pickle.pkl'
&gt;&gt;&gt; pkl_dict = {&quot;A&quot;: np.ones([3, 3]),
                &quot;B&quot;: datetime.today(),
                &quot;C&quot;: SomeEnum.some_name}
&gt;&gt;&gt; save_json(output_pkl, pkl_dict)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>obj</code></strong> :&ensp;<code>Any</code></dt>
<dd>Any object serializable</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Path where to write the pickle</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_obj(obj: Any, path: Union[str, CloudPath, Path]) -&gt; None:
    &#34;&#34;&#34;
    Save an object as a pickle (can save any Python objects).

    ```python
    &gt;&gt;&gt; output_pkl = &#39;D:\\path\\to\\pickle.pkl&#39;
    &gt;&gt;&gt; pkl_dict = {&#34;A&#34;: np.ones([3, 3]),
                    &#34;B&#34;: datetime.today(),
                    &#34;C&#34;: SomeEnum.some_name}
    &gt;&gt;&gt; save_json(output_pkl, pkl_dict)
    ```

    Args:
        obj (Any): Any object serializable
        path (Union[str, CloudPath, Path]): Path where to write the pickle
    &#34;&#34;&#34;
    with open(path, &#34;wb+&#34;) as file:
        pickle.dump(obj, file)</code></pre>
</details>
</dd>
<dt id="sertit.files.load_obj"><code class="name flex">
<p>def <span class="ident">load_obj</span>(</p><p>path)</p>
</code></dt>
<dd>
<div class="desc"><p>Load a pickled object.</p>
<pre><code class="language-python">&gt;&gt;&gt; output_pkl = 'D:\path\to\pickle.pkl'
&gt;&gt;&gt; load_obj(output_pkl)
{&quot;A&quot;: np.ones([3, 3]), &quot;B&quot;: datetime.today(), &quot;C&quot;: SomeEnum.some_name}
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>Union[str, CloudPath, Path]</code></dt>
<dd>Path of the pickle</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>object (Any): Pickled object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_obj(path: Union[str, CloudPath, Path]) -&gt; Any:
    &#34;&#34;&#34;
    Load a pickled object.

    ```python
    &gt;&gt;&gt; output_pkl = &#39;D:\\path\\to\\pickle.pkl&#39;
    &gt;&gt;&gt; load_obj(output_pkl)
    {&#34;A&#34;: np.ones([3, 3]), &#34;B&#34;: datetime.today(), &#34;C&#34;: SomeEnum.some_name}
    ```

    Args:
        path (Union[str, CloudPath, Path]): Path of the pickle
    Returns:
        object (Any): Pickled object

    &#34;&#34;&#34;
    with open(path, &#34;rb&#34;) as file:
        return pickle.load(file)</code></pre>
</details>
</dd>
<dt id="sertit.files.get_file_in_dir"><code class="name flex">
<p>def <span class="ident">get_file_in_dir</span>(</p><p>directory, <br>pattern_str, <br>extension=None, <br>filename_only=False, <br>get_list=False, <br>exact_name=False)</p>
</code></dt>
<dd>
<div class="desc"><p>Get one or all matching files (pattern + extension) from inside a directory.</p>
<p>Note that the pattern is a regex with glob's convention, ie. <code>*pattern*</code>.</p>
<p>If <code>exact_name</code> is <code>False</code>, the searched pattern will be <code>*{pattern}*.{extension}</code>, else <code>{pattern}.{extension}</code>.</p>
<pre><code class="language-python">&gt;&gt;&gt; directory = 'D:\path\to\dir'
&gt;&gt;&gt; os.listdir(directory)
[&quot;haha.txt&quot;, &quot;huhu1.txt&quot;, &quot;huhu1.geojson&quot;, &quot;hoho.txt&quot;]

&gt;&gt;&gt; get_file_in_dir(directory, &quot;huhu&quot;)
'D:\path\to\dir\huhu1.geojson'

&gt;&gt;&gt; get_file_in_dir(directory, &quot;huhu&quot;, extension=&quot;txt&quot;)
'D:\path\to\dir\huhu1.txt'

&gt;&gt;&gt; get_file_in_dir(directory, &quot;huhu&quot;, get_list=True)
['D:\path\to\dir\huhu1.txt', 'D:\path\to\dir\huhu1.geojson']

&gt;&gt;&gt; get_file_in_dir(directory, &quot;huhu&quot;, filename_only=True, get_list=True)
['huhu1.txt', 'huhu1.geojson']

&gt;&gt;&gt; get_file_in_dir(directory, &quot;huhu&quot;, get_list=True, exact_name=True)
[]
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>directory</code></strong> :&ensp;<code>str</code></dt>
<dd>Directory where to find the files</dd>
<dt><strong><code>pattern_str</code></strong> :&ensp;<code>str</code></dt>
<dd>Pattern wanted as a string, with glob's convention.</dd>
<dt><strong><code>extension</code></strong> :&ensp;<code>str</code></dt>
<dd>Extension wanted, optional. With or without point. (<code>yaml</code> or <code>.yaml</code> accepted)</dd>
<dt><strong><code>filename_only</code></strong> :&ensp;<code>bool</code></dt>
<dd>Get only the filename</dd>
<dt><strong><code>get_list</code></strong> :&ensp;<code>bool</code></dt>
<dd>Get the whole list of matching files</dd>
<dt><strong><code>exact_name</code></strong> :&ensp;<code>bool</code></dt>
<dd>Get the exact name (without adding <code>*</code> before and after the given pattern)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[CloudPath, Path, list]</code></dt>
<dd>File</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_file_in_dir(
    directory: Union[str, CloudPath, Path],
    pattern_str: str,
    extension: str = None,
    filename_only: bool = False,
    get_list: bool = False,
    exact_name: bool = False,
) -&gt; Union[CloudPath, Path, list]:
    &#34;&#34;&#34;
    Get one or all matching files (pattern + extension) from inside a directory.

    Note that the pattern is a regex with glob&#39;s convention, ie. `*pattern*`.

    If `exact_name` is `False`, the searched pattern will be `*{pattern}*.{extension}`, else `{pattern}.{extension}`.

    ```python
    &gt;&gt;&gt; directory = &#39;D:\\path\\to\\dir&#39;
    &gt;&gt;&gt; os.listdir(directory)
    [&#34;haha.txt&#34;, &#34;huhu1.txt&#34;, &#34;huhu1.geojson&#34;, &#34;hoho.txt&#34;]

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;)
    &#39;D:\\path\\to\\dir\\huhu1.geojson&#39;

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, extension=&#34;txt&#34;)
    &#39;D:\\path\\to\\dir\\huhu1.txt&#39;

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, get_list=True)
    [&#39;D:\\path\\to\\dir\\huhu1.txt&#39;, &#39;D:\\path\\to\\dir\\huhu1.geojson&#39;]

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, filename_only=True, get_list=True)
    [&#39;huhu1.txt&#39;, &#39;huhu1.geojson&#39;]

    &gt;&gt;&gt; get_file_in_dir(directory, &#34;huhu&#34;, get_list=True, exact_name=True)
    []
    ```

    Args:
        directory (str): Directory where to find the files
        pattern_str (str): Pattern wanted as a string, with glob&#39;s convention.
        extension (str): Extension wanted, optional. With or without point. (`yaml` or `.yaml` accepted)
        filename_only (bool): Get only the filename
        get_list (bool): Get the whole list of matching files
        exact_name (bool): Get the exact name (without adding `*` before and after the given pattern)

    Returns:
        Union[CloudPath, Path, list]: File
    &#34;&#34;&#34;
    directory = AnyPath(directory)

    # Glob pattern
    if exact_name:
        glob_pattern = pattern_str
    else:
        glob_pattern = &#34;*&#34; + pattern_str + &#34;*&#34;
    if extension:
        if not extension.startswith(&#34;.&#34;):
            extension = &#34;.&#34; + extension
        glob_pattern += extension

    # Search for the pattern in the directory
    file_list = list(directory.glob(glob_pattern))

    if len(file_list) == 0:
        raise FileNotFoundError(
            f&#34;File with pattern {glob_pattern} not found in {directory}&#34;
        )

    # Return list, file path or file name
    if get_list:
        file = file_list
    else:
        if len(file_list) &gt; 1:
            LOGGER.warning(
                &#34;More than one file corresponding to the pattern %s has been found here %s. &#34;
                &#34;Only the first item will be returned.&#34;,
                glob_pattern,
                directory,
            )
        file = file_list[0]
        if filename_only:
            file = file.name

    return file</code></pre>
</details>
</dd>
<dt id="sertit.files.hash_file_content"><code class="name flex">
<p>def <span class="ident">hash_file_content</span>(</p><p>file_content, <br>len_param=5)</p>
</code></dt>
<dd>
<div class="desc"><p>Hash a file into a unique str.</p>
<pre><code class="language-python">&gt;&gt;&gt; read_json(&quot;path\to\json.json&quot;)
{&quot;A&quot;: 1, &quot;B&quot;: 2}

&gt;&gt;&gt; hash_file_content(str(file_content))
&quot;d3fad5bdf9&quot;
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_content</code></strong> :&ensp;<code>str</code></dt>
<dd>File content</dd>
<dt><strong><code>len_param</code></strong> :&ensp;<code>int</code></dt>
<dd>Length parameter for the hash (length of the key will be 2x this number)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Hashed file content</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hash_file_content(file_content: str, len_param: int = 5) -&gt; str:
    &#34;&#34;&#34;
    Hash a file into a unique str.

    ```python
    &gt;&gt;&gt; read_json(&#34;path\\to\\json.json&#34;)
    {&#34;A&#34;: 1, &#34;B&#34;: 2}

    &gt;&gt;&gt; hash_file_content(str(file_content))
    &#34;d3fad5bdf9&#34;
    ```

    Args:
        file_content (str): File content
        len_param (int): Length parameter for the hash (length of the key will be 2x this number)

    Returns:
        str: Hashed file content
    &#34;&#34;&#34;
    hasher = hashlib.shake_256()
    hasher.update(str.encode(file_content))
    return hasher.hexdigest(len_param)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="sertit.files.CustomDecoder"><code class="flex name class">
<span>class <span class="ident">CustomDecoder</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Decoder for JSON with methods for datetimes</p>
<p><code>object_hook</code>, if specified, will be called with the result
of every JSON object decoded and its return value will be used in
place of the given <code>dict</code>.
This can be used to provide custom
deserializations (e.g. to support JSON-RPC class hinting).</p>
<p><code>object_pairs_hook</code>, if specified will be called with the result of
every JSON object decoded with an ordered list of pairs.
The return
value of <code>object_pairs_hook</code> will be used instead of the <code>dict</code>.
This feature can be used to implement custom decoders.
If <code>object_hook</code> is also defined, the <code>object_pairs_hook</code> takes
priority.</p>
<p><code>parse_float</code>, if specified, will be called with the string
of every JSON float to be decoded. By default this is equivalent to
float(num_str). This can be used to use another datatype or parser
for JSON floats (e.g. decimal.Decimal).</p>
<p><code>parse_int</code>, if specified, will be called with the string
of every JSON int to be decoded. By default this is equivalent to
int(num_str). This can be used to use another datatype or parser
for JSON integers (e.g. float).</p>
<p><code>parse_constant</code>, if specified, will be called with one of the
following strings: -Infinity, Infinity, NaN.
This can be used to raise an exception if invalid JSON numbers
are encountered.</p>
<p>If <code>strict</code> is false (true is the default), then control
characters will be allowed inside strings.
Control characters in
this context are those with character codes in the 0-31 range,
including <code>'\t'</code> (tab), <code>'\n'</code>, <code>'\r'</code> and <code>'\0'</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CustomDecoder(JSONDecoder):
    &#34;&#34;&#34;Decoder for JSON with methods for datetimes&#34;&#34;&#34;

    # pylint: disable=W0221
    # Override the default method
    def __init__(self, *args, **kwargs):
        json.JSONDecoder.__init__(self, object_hook=self.object_hook, *args, **kwargs)

    # pylint: disable=E0202, R0201
    # - An attribute defined in json.decoder line 319 hides this method (method-hidden)
    # - Method could be a function (no-self-use)
    def object_hook(self, obj: Any):
        &#34;&#34;&#34;
        Overload of object_hook function that deals with `datetime.datetime`

        Args:
            obj (dict): Dict containing objects to decode from JSON

        Returns:
            dict: Dict with decoded object
        &#34;&#34;&#34;
        for key, val in obj.items():
            if isinstance(val, str):
                try:
                    # Date -&gt; Encoder saves dates as isoformat
                    obj[key] = date.fromisoformat(val)
                except ValueError:
                    try:
                        # Datetime -&gt; Encoder saves datetimes as isoformat
                        obj[key] = datetime.fromisoformat(val)
                    except ValueError:
                        obj[key] = val
            else:
                obj[key] = val
        return obj</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>json.decoder.JSONDecoder</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sertit.files.CustomDecoder.object_hook"><code class="name flex">
<p>def <span class="ident">object_hook</span>(</p><p>self, <br>obj)</p>
</code></dt>
<dd>
<div class="desc"><p>Overload of object_hook function that deals with <code>datetime.datetime</code></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>obj</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dict containing objects to decode from JSON</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Dict with decoded object</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def object_hook(self, obj: Any):
    &#34;&#34;&#34;
    Overload of object_hook function that deals with `datetime.datetime`

    Args:
        obj (dict): Dict containing objects to decode from JSON

    Returns:
        dict: Dict with decoded object
    &#34;&#34;&#34;
    for key, val in obj.items():
        if isinstance(val, str):
            try:
                # Date -&gt; Encoder saves dates as isoformat
                obj[key] = date.fromisoformat(val)
            except ValueError:
                try:
                    # Datetime -&gt; Encoder saves datetimes as isoformat
                    obj[key] = datetime.fromisoformat(val)
                except ValueError:
                    obj[key] = val
        else:
            obj[key] = val
    return obj</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="sertit.files.CustomEncoder"><code class="flex name class">
<span>class <span class="ident">CustomEncoder</span></span>
<span>(</span><span>*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Encoder for JSON with methods for datetimes and np.int64</p>
<p>Constructor for JSONEncoder, with sensible defaults.</p>
<p>If skipkeys is false, then it is a TypeError to attempt
encoding of keys that are not str, int, float or None.
If
skipkeys is True, such items are simply skipped.</p>
<p>If ensure_ascii is true, the output is guaranteed to be str
objects with all incoming non-ASCII characters escaped.
If
ensure_ascii is false, the output can contain non-ASCII characters.</p>
<p>If check_circular is true, then lists, dicts, and custom encoded
objects will be checked for circular references during encoding to
prevent an infinite recursion (which would cause an OverflowError).
Otherwise, no such check takes place.</p>
<p>If allow_nan is true, then NaN, Infinity, and -Infinity will be
encoded as such.
This behavior is not JSON specification compliant,
but is consistent with most JavaScript based encoders and decoders.
Otherwise, it will be a ValueError to encode such floats.</p>
<p>If sort_keys is true, then the output of dictionaries will be
sorted by key; this is useful for regression tests to ensure
that JSON serializations can be compared on a day-to-day basis.</p>
<p>If indent is a non-negative integer, then JSON array
elements and object members will be pretty-printed with that
indent level.
An indent level of 0 will only insert newlines.
None is the most compact representation.</p>
<p>If specified, separators should be an (item_separator, key_separator)
tuple.
The default is (', ', ': ') if <em>indent</em> is <code>None</code> and
(',', ': ') otherwise.
To get the most compact JSON representation,
you should specify (',', ':') to eliminate whitespace.</p>
<p>If specified, default is a function that gets called for objects
that can't otherwise be serialized.
It should return a JSON encodable
version of the object or raise a <code>TypeError</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CustomEncoder(JSONEncoder):
    &#34;&#34;&#34;Encoder for JSON with methods for datetimes and np.int64&#34;&#34;&#34;

    # pylint: disable=W0221
    def default(self, obj):
        &#34;&#34;&#34;Overload of the default method&#34;&#34;&#34;
        if isinstance(obj, (date, datetime)):
            out = obj.isoformat()
        elif isinstance(obj, (np.int64, np.int32)):
            out = int(obj)
        elif isinstance(obj, Enum):
            out = obj.value
        elif isinstance(obj, (CloudPath, Path)):
            out = str(obj)
        else:
            out = json.JSONEncoder.default(self, obj)

        return out</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>json.encoder.JSONEncoder</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="sertit.files.CustomEncoder.default"><code class="name flex">
<p>def <span class="ident">default</span>(</p><p>self, <br>obj)</p>
</code></dt>
<dd>
<div class="desc"><p>Overload of the default method</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def default(self, obj):
    &#34;&#34;&#34;Overload of the default method&#34;&#34;&#34;
    if isinstance(obj, (date, datetime)):
        out = obj.isoformat()
    elif isinstance(obj, (np.int64, np.int32)):
        out = int(obj)
    elif isinstance(obj, Enum):
        out = obj.value
    elif isinstance(obj, (CloudPath, Path)):
        out = str(obj)
    else:
        out = json.JSONEncoder.default(self, obj)

    return out</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="Home" href="/sertit-utils/">
<img src="https://sertit.pages.sertit.unistra.fr/sertit-utils/sertit_utils.png"
alt="logo"
style="width:40%;"/>
</a>
</header>
<form>
<input id="lunr-search" name="q" placeholder=" Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sertit" href="index.html">sertit</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sertit.files.get_root_path" href="#sertit.files.get_root_path">get_root_path</a></code></li>
<li><code><a title="sertit.files.listdir_abspath" href="#sertit.files.listdir_abspath">listdir_abspath</a></code></li>
<li><code><a title="sertit.files.to_abspath" href="#sertit.files.to_abspath">to_abspath</a></code></li>
<li><code><a title="sertit.files.real_rel_path" href="#sertit.files.real_rel_path">real_rel_path</a></code></li>
<li><code><a title="sertit.files.extract_file" href="#sertit.files.extract_file">extract_file</a></code></li>
<li><code><a title="sertit.files.extract_files" href="#sertit.files.extract_files">extract_files</a></code></li>
<li><code><a title="sertit.files.get_archived_file_list" href="#sertit.files.get_archived_file_list">get_archived_file_list</a></code></li>
<li><code><a title="sertit.files.get_archived_rio_path" href="#sertit.files.get_archived_rio_path">get_archived_rio_path</a></code></li>
<li><code><a title="sertit.files.read_archived_xml" href="#sertit.files.read_archived_xml">read_archived_xml</a></code></li>
<li><code><a title="sertit.files.archive" href="#sertit.files.archive">archive</a></code></li>
<li><code><a title="sertit.files.add_to_zip" href="#sertit.files.add_to_zip">add_to_zip</a></code></li>
<li><code><a title="sertit.files.get_filename" href="#sertit.files.get_filename">get_filename</a></code></li>
<li><code><a title="sertit.files.remove" href="#sertit.files.remove">remove</a></code></li>
<li><code><a title="sertit.files.remove_by_pattern" href="#sertit.files.remove_by_pattern">remove_by_pattern</a></code></li>
<li><code><a title="sertit.files.copy" href="#sertit.files.copy">copy</a></code></li>
<li><code><a title="sertit.files.find_files" href="#sertit.files.find_files">find_files</a></code></li>
<li><code><a title="sertit.files.read_json" href="#sertit.files.read_json">read_json</a></code></li>
<li><code><a title="sertit.files.save_json" href="#sertit.files.save_json">save_json</a></code></li>
<li><code><a title="sertit.files.save_obj" href="#sertit.files.save_obj">save_obj</a></code></li>
<li><code><a title="sertit.files.load_obj" href="#sertit.files.load_obj">load_obj</a></code></li>
<li><code><a title="sertit.files.get_file_in_dir" href="#sertit.files.get_file_in_dir">get_file_in_dir</a></code></li>
<li><code><a title="sertit.files.hash_file_content" href="#sertit.files.hash_file_content">hash_file_content</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="sertit.files.CustomDecoder" href="#sertit.files.CustomDecoder">CustomDecoder</a></code></h4>
<ul>
<li>
</li>
<li>
<ul class="">
<li><code><a title="sertit.files.CustomDecoder.object_hook" href="#sertit.files.CustomDecoder.object_hook">object_hook</a></code></li>
</ul>
</li>
<li>
</li>
<li>
</li>
</ul>
</li>
<li>
<h4><code><a title="sertit.files.CustomEncoder" href="#sertit.files.CustomEncoder">CustomEncoder</a></code></h4>
<ul>
<li>
</li>
<li>
<ul class="">
<li><code><a title="sertit.files.CustomEncoder.default" href="#sertit.files.CustomEncoder.default">default</a></code></li>
</ul>
</li>
<li>
</li>
<li>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>